<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta content="width=device-width, initial-scale=1" name="viewport" />
  <meta content="#ffffff" name="theme-color" />
  <meta content="#da532c" name="msapplication-TileColor" />

  
  <link href='&#x2F;icons&#x2F;site.webmanifest' rel="manifest" />
  
  
  <link color="#5bbad5" href='&#x2F;icons&#x2F;safari-pinned-tab.svg' rel="mask-icon" />
  
  
  <link href='&#x2F;icons&#x2F;favicon-16x16.png' rel="icon" sizes="16x16" type="image/png" />
  
  
  <link href='&#x2F;icons&#x2F;favicon-32x32.png' rel="icon" sizes="32x32" type="image/png" />
  
  
  <link href='&#x2F;icons&#x2F;apple-touch-icon.png' rel="apple-touch-icon" sizes="180x180" />
  

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/galleria@1.6.1/dist/themes/folio/galleria.folio.min.css" integrity="sha384-+rY0QD+LRnTOquDMzGa9lXU6jIwdiQuwCJQ2cdcW0qeP/0UbjQCZlXnRsUMA+9pH" crossorigin="anonymous">
  

  
  <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v2.6.1/mapbox-gl.css" integrity="sha384-oGm59HWAkwO32h2w8u0B98wKBZJwd6MbWtAJwQKCTffZjOXHXrnyv9Syjovgc+UV" crossorigin="anonymous">
  

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.1/css/academicons.min.css" integrity="sha384-FIue+PI4SsI9XfHCz8dBLg33b0c1fMJgNU3X//L26FYbGnlSEfWmNT7zgWc2N9b6" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha384-DyZ88mC6Up2uqS4h/KRgHuoeGwBcD4Ng9SiP4dIRy0EXTlnuz47vAwmeGwVChigm" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" integrity="sha256-rTpdO0HXBCNpreAHcu6tB2Ppg515Vo+5GtYSsnNLz+8=" crossorigin="anonymous">
  <link href="https://nlp-with-fewer-labels.github.io/deep-thought.css" rel="stylesheet" />
  
  

  <title>
    
NLP with Fewer Labels | Related Resources

  </title>

  
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-176984489-2"></script>
  <script type="text/javascript">
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());
    gtag("config", "UA-176984489-2");
  </script>
  
  

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>

  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mathtex-script-type.min.js" integrity="sha384-jiBVvJ8NGGj5n7kJaiWwWp9AjC+Yh8rhZY3GtAX8yU28azcLgoRo4oukO87g7zDT" crossorigin="anonymous"></script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
  
  
</head>

<body class="has-background-white">
  <nav aria-label="section navigation" class="navbar is-light" role="navigation">
    <div class="container">
      <div class="navbar-brand">
        <a class="navbar-item is-size-5 has-text-weight-bold" href="https:&#x2F;&#x2F;nlp-with-fewer-labels.github.io">NLP with Fewer Labels</a>
        <a aria-expanded="false" aria-label="menu" class="navbar-burger burger" data-target="navMenu" role="button">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu" id="navMenu">
        <div class="navbar-end has-text-centered">
          
          
          
          <a class="navbar-item has-text-weight-semibold" href="https:&#x2F;&#x2F;nlp-with-fewer-labels.github.io&#x2F;">
            Home
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="https:&#x2F;&#x2F;nlp-with-fewer-labels.github.io&#x2F;News">
            News
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="https:&#x2F;&#x2F;nlp-with-fewer-labels.github.io&#x2F;Team">
            Team
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="https:&#x2F;&#x2F;nlp-with-fewer-labels.github.io&#x2F;Publications">
            Publications
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="https:&#x2F;&#x2F;nlp-with-fewer-labels.github.io&#x2F;Achievements">
            Achievements
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="https:&#x2F;&#x2F;nlp-with-fewer-labels.github.io&#x2F;Resources">
            Related Resources
          </a>
          
          
          
          <a class="navbar-item" id="nav-search" title="Search" data-target="#search-modal">
            <span class="icon">
              <i class="fas fa-search"></i>
            </span>
          </a>
          <a class="navbar-item" id="dark-mode" title="Switch to dark theme">
            <span class="icon">
              <i class="fas fa-adjust"></i>
            </span>
          </a>
        </div>
      </div>
    </div>
  </nav>

  
  

  
<section class="section">
  <div class="container">
    <div class="has-text-centered">
      <h1 class="title is-2">Related Resources</h1>
      <p class="subtitle is-4">Paper list, related tutorials, benchmarks, and code here.</p>
    </div>
    <div class="content">
      <br />
<h1 id="papers">Papers</h1>
<h3 id="previous-publications-by-our-team">Previous Publications by Our Team</h3>
<!-- 根据时间倒序来排列，最新的放前面，之后按照标题首字母a-z排序。 -->
<!-- 格式与下面示例相同：标题加粗，作者全称全部列出来并斜体，后面是会议、年份，或期刊名称，最后面提供pdf、code、bib、poster等资源的链接。元素之间用英文句号分隔。 -->
<!-- 注意是四级标题了！ -->
<!-- 以下为示例： -->
<!-- - **Inducing Positive Perspectives with Text Reframing**. *Caleb Ziems, Minzhi Li, Anthony Zhang, Diyi Yang*. ACL 2022. [[pdf](https://aclanthology.org/2022.acl-long.257.pdf)][[code](https://github.com/SALT-NLP/positive-frames)][[bib](https://aclanthology.org/2022.acl-long.257.bib)][[poster](https://www.baidu.com/)] -->
<ul>
<li>
<p><strong>BBTv2: Towards a Gradient-Free Future with Large Language Models</strong>. <em>Tianxiang Sun, Zhengfu He, Hong Qian, Yunhua Zhou, Xuanjing Huang, Xipeng Qiu</em>. EMNLP 2022. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://arxiv.org/abs/2205.11200">pdf</a>] [<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/txsun1997/Black-Box-Tuning">code</a>]</p>
</li>
<li>
<p><strong>Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts</strong>. <em>Xiangyang Liu, Tianxiang Sun, Xuanjing Huang, Xipeng Qiu</em>. Findings of EMNLP 2022. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://arxiv.org/abs/2210.11292">pdf</a>] [<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/xyltt/LPT">code</a>]</p>
</li>
<li>
<p><strong>Black-Box Tuning for Language-Model-as-a-Service</strong>. <em>Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, Xipeng Qiu</em>. ICML 2022. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://proceedings.mlr.press/v162/sun22e/sun22e.pdf">pdf</a>] [<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/txsun1997/Black-Box-Tuning">code</a>] [<a rel="noopener nofollow noreferrer" target="_blank" href="https://txsun1997.github.io/slides/bbt.pdf">slides</a>]</p>
</li>
<li>
<p><strong>Allocating Large Vocabulary Capacity for Cross-Lingual Language Model Pre-Training</strong>. <em>Bo Zheng, Li Dong, Shaohan Huang, Saksham Singhal, Wanxiang Che, Ting Liu, Xia Song, Furu Wei</em>. EMNLP 2021. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.emnlp-main.257.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://paperswithcode.com/paper/allocating-large-vocabulary-capacity-for">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.emnlp-main.257.bib">bib</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.emnlp-main.257.mp4">poster</a>]</p>
</li>
<li>
<p><strong>C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling</strong>. <em>Yutai Hou, Sanyuan Chen, Wanxiang Che, Cheng Chen, Ting Liu</em>. AAAI 2021. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://www.aaai.org/AAAI21Papers/AAAI-10147.HouY.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/Sanyuan-Chen/C2C-DA">code</a>]</p>
</li>
<li>
<p><strong>Consistency Regularization for Cross-Lingual Fine-Tuning</strong>. <em>Bo Zheng, Li Dong, Shaohan Huang, Wenhui Wang, Zewen Chi, Saksham Singhal, Wanxiang Che, Ting Liu, Xia Song, Furu Wei</em>. ACL-IJCNLP 2021. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.acl-long.264.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/bozheng-hit/xTune">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.acl-long.264.bib">bib</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.acl-long.264.mp4">poster</a>]</p>
</li>
<li>
<p><strong>Few-shot Learning for Multi-label Intent Detection</strong>. <em>Yutai Hou, Yongkui Lai, Yushan Wu, Wanxiang Che, Ting Liu</em>. AAAI 2021. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/17541/17348">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/AtmaHou/FewShotMultiLabel">code</a>]</p>
</li>
<li>
<p><strong>Learning to Bridge Metric Spaces: Few-shot Joint Learning of Intent Detection and Slot Filling</strong>. <em>Yutai Hou, Yongkui Lai, Cheng Chen, Wanxiang Che, Ting Liu</em>. ACL-IJCNLP 2021. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.findings-acl.282.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/AtmaHou/FewShotJoint">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.findings-acl.282.bib">bib</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2021.findings-acl.282.mp4">poster</a>]</p>
</li>
<li>
<p><strong>Pre-Training With Whole Word Masking for Chinese BERT</strong>. <em>Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Ziqing Yang</em>. TASLP 2021. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://ymcui.com/pdf/chinese-bert-wwm.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/ymcui/Chinese-BERT-wwm">code</a>]</p>
</li>
<li>
<p><strong>CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot Cross-Lingual NLP</strong>. <em>Libo Qin, Minheng Ni, Yue Zhang, Wanxiang Che</em>. IJCAI 2020. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://www.ijcai.org/proceedings/2020/0533.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/kodenii/CoSDA-ML">code</a>]</p>
</li>
<li>
<p><strong>Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network</strong>. <em>Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu, Ting Liu</em>. ACL 2020. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2020.acl-main.128.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/AtmaHou/FewShotTagging">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2020.acl-main.128.bib">bib</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="http://slideslive.com/38929212">poster</a>]</p>
</li>
<li>
<p><strong>Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting</strong>. <em>Sanyuan Chen, Yutai Hou, Yiming Cui, Wanxiang Che, Ting Liu, Xiangzhan Yu</em>. EMNLP 2020. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2020.emnlp-main.634.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/Sanyuan-Chen/RecAdam">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2020.emnlp-main.634.bib">bib</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://slideslive.com/38938976">poster</a>]</p>
</li>
<li>
<p><strong>Revisiting Pre-Trained Models for Chinese Natural Language Processing</strong>. <em>Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, Guoping Hu</em>. EMNLP 2020. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2020.findings-emnlp.58.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/ymcui/MacBERT">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/2020.findings-emnlp.58.bib">bib</a>]</p>
</li>
<li>
<p><strong>Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing</strong>. <em>Yuxuan Wang, Wanxiang Che, Jiang Guo, Yijia Liu, Ting Liu</em>. EMNLP 2019. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/D19-1575.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/WangYuxuan93/CLBT">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/D19-1575.bib">bib</a>]</p>
</li>
<li>
<p><strong>Sequence-to-Sequence Data Augmentation for Dialogue Language Understanding</strong>. <em>Yutai Hou, Yijia Liu, Wanxiang Che, Ting Liu</em>. COLING 2018. [<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/C18-1105.pdf">pdf</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/AtmaHou/Seq2SeqDataAugmentationForLU">code</a>][<a rel="noopener nofollow noreferrer" target="_blank" href="https://aclanthology.org/C18-1105.bib">bib</a>]</p>
</li>
</ul>
<h3 id="other-links">Other Links</h3>
<h4 id="awesome-meta-learning">Awesome Meta Learning</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/sudharsan13296/Awesome-Meta-Learning">https://github.com/sudharsan13296/Awesome-Meta-Learning</a></p>
<p><strong>Tags:</strong> Meta Learning, MAML, Few-Shot, Zero-Shot</p>
<p><strong>Intro:</strong> A curated list of Meta Learning papers, code, books, blogs, videos, datasets and other resources.</p>
<br />
<h4 id="few-shot-learning-literature">Few-shot Learning Literature</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/wutong8023/Awesome_Few_Shot_Learning">https://github.com/wutong8023/Awesome_Few_Shot_Learning</a></p>
<p><strong>Tags:</strong> Few-Shot, Continual Learning, Information Extraction</p>
<p><strong>Intro:</strong> A collection of few-shot learning literature categorized by the Published Venue.</p>
<br />
<h4 id="awesome-few-shot-learning-in-nlp">Awesome Few-shot Learning in NLP</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/zhjohnchan/awesome-few-shot-learning-in-nlp">https://github.com/zhjohnchan/awesome-few-shot-learning-in-nlp</a></p>
<p><strong>Tags:</strong> Few-Shot</p>
<p><strong>Intro:</strong> A collection of few-shot learning research papers published in 2019-2021. </p>
<br />
<h4 id="meta-learning-for-nlp-papers">Meta learning for NLP - Papers</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/ha-lins/MetaLearning4NLP-Papers">https://github.com/ha-lins/MetaLearning4NLP-Papers</a></p>
<p><strong>Tags:</strong> Meta Learning, Fundamental NLP Tasks, Dialog System</p>
<p><strong>Intro:</strong> A list of Meta Learning papers classified by application scenarios. </p>
<br />
<h4 id="few-shot-learning-for-nlp-papers">Few-shot learning for NLP - Papers</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/Duan-JM/awesome-papers-fewshot">https://github.com/Duan-JM/awesome-papers-fewshot</a></p>
<p><strong>Tags:</strong> Few-Shot, Pre-trained Model, Prompt-based method, Dialogue</p>
<p><strong>Intro:</strong> This repo focuses on collecting papers published on top conferences in few-shot learning area and separates papers into different files according to their categories. </p>
<h1 id="datasets">Datasets</h1>
<!-- 注意是四级标题了！ -->
<h4 id="fewjoint">FewJoint</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/AtmaHou/MetaDialog">https://github.com/AtmaHou/MetaDialog</a></p>
<p><strong>Tags:</strong> Task-oriented Dialogue, NLU</p>
<p><strong>Intro:</strong> FewJoint is a novel FSL benchmark for joint multi-task learning, to promote FSL research of the NLP area. To reflect the real word NLP complexities beyond simple N-classification, FewJoint adopts a sophisticated and important NLP problem for the benchmark: Task-oriented Dialogue Language Understanding. Task-oriented Dialogue is a rising research area that develops dialogue systems to help users to achieve goals, such as booking tickets. Language Under-standing is a fundamental module of Task-oriented Dialogue that extracts semantic frames from user utterances. It contains two subtasks: Intent Detection and Slot Tagging. With the Slot Tagging task, FewJoint benchmark covers one of the most common structure prediction problems: sequence labeling. Besides, thanks to the natural dependency between Intent Detection and Slot Tagging, FewJoint  can embody the multi-task challenge of NLP problems. To conquer randomness and make an adequate evaluation, FewJoint includes 59 different dialogue domains from real industrial API, which is a considerable domain amount compared to all existing few-shot and dialogue data. </p>
<br />
<h4 id="flex">FLEX</h4>
<p><strong>Link:</strong> [https://github.com/allenai/flex][https://github.com/allenai/flex]</p>
<p><strong>Intro:</strong> FLEX is a few-shot learning NLP benchmark that contains four few-shot settings and zero-shot evaluation across 20 NLP datasets (natural language inference, relation classification,  entity typing, etc.). FLEX could evaluate four transfer learning settings, including class transfer, domain transfer, task transfer, and pretraining transfer. The suite also contain sampling tools that could create episodes with class imbalance. </p>
<h4 id="crossfit">CrossFit</h4>
<p><strong>Link:</strong> [https://github.com/INK-USC/CrossFit][https://github.com/INK-USC/CrossFit]</p>
<p><strong>Intro:</strong> CrossFit is a Few-shot challenge of 160 different NLP tasks collected from existing open-access datasets. All tasks in this collection are transformed into a text-to-text format. There are four general types of the included datasets, which are: classification (sentiment classification, paraphrase identification, natural language inference, etc.), question answering (reading comprehension, multi-choice QA, closed-book QA), conditional generation (summarization, dialogue), and others.</p>
<br />
<h4 id="few-nerd">Few-NERD</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/thunlp/Few-NERD">https://github.com/thunlp/Few-NERD</a></p>
<p><strong>Tags:</strong> Named Entity Recognition</p>
<p><strong>Intro:</strong> Few-NERD is a manually annotated few-shot named entity recognition (NER) dataset, consisting of 8 coarse-grained types, 66 fine-grained types, 188,200 sentences, 491,711 entities and 4,601,223 tokens. 
There benchmarks are included to assess different levels of generalization fo NER models. Few-NERD (SUP) is a fully supervised NER benchmark that is verified to be more difficult that conventional datasets. Few-NERD (INTER) and Few-NERD (INTRA) are episodic benchmarks that adopts N way K~2K shot sampling in this sequence labeling task.</p>
<br />
<h4 id="fewrel">FewRel</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/thunlp/FewRel">https://github.com/thunlp/FewRel</a></p>
<p><strong>Tags:</strong> Relation Extraction</p>
<p><strong>Intro:</strong> FewRel is a large-scale few-shot relation extraction dataset, which contains more than one hundred relations and tens of thousands of annotated instances cross different domains. The benchmark is established by N way K shot sentence-level classification. The second edition of the dataset, FewRel 2.0,  adds domain adaptation (DA) and none-of-the-above (NOTA) detection challenges to evaluate cross-domain generalization more comprehensively.</p>
<h1 id="talks">Talks</h1>
<h4 id="zero-and-few-shot-nlp-with-pretrained-language-models">Zero- and Few-Shot NLP with Pretrained Language Models</h4>
<p><strong>Link:</strong> <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/allenai/acl2022-zerofewshot-tutorial">https://github.com/allenai/acl2022-zerofewshot-tutorial</a></p>
<p><strong>Intro:</strong> The ability to efficiently learn from little-to-no data is critical to applying NLP to tasks where data collection is costly or otherwise difficult. This is a challenging setting both academically and practically---particularly because training neutral models typically require large amount of labeled data. More recently, advances in pretraining on unlabelled data have brought up the potential of better zero-shot or few-shot learning (Devlin et al., 2019; Brown et al., 2020). In particular, over the past year, a great deal of research has been conducted to better learn from limited data using large-scale language models. In this tutorial, we aim at bringing interested NLP researchers up to speed about the recent and ongoing techniques for zero- and few-shot learning with pretrained language models. Additionally, our goal is to reveal new research opportunities to the audience, which will hopefully bring us closer to address existing challenges in this domain.</p>

    </div>
    <div class="columns is-centered">
      <div class="column is-9">
        
        
        

        
      </div>
    </div>
  </div>
</section>


  
  <section class="modal" id="search-modal">
    <div class="modal-background"></div>
    <div class="modal-card">
      <header class="modal-card-head">
        <p class="modal-card-title">Search</p>
      </header>
      <section class="modal-card-body">
        <div class="field mb-2">
          <div class="control">
            <input class="input" id="search" placeholder="Search this website." type="search" />
          </div>
        </div>
        <div class="search-results">
          <div class="search-results__items"></div>
        </div>
      </section>
    </div>
    <button aria-label="close" class="modal-close is-large"></button>
  </section>
  


  
  
  

  
  

  
  <footer class="footer py-4">
    <div class="content has-text-centered">
      <p>
        Built with
        <span class="icon-text">
          <span class="icon">
            <i class="fas fa-code"></i>
          </span>
          <span>code</span>
        </span>
        and
        <span class="icon-text">
          <span class="icon">
            <i class="fas fa-heart"></i>
          </span>
          <span>love</span>
        </span>
      </p>
      <p>
        Powered by
        <span class="icon-text">
          <span class="icon">
            <i class="fas fa-power-off"></i>
          </span>
          <span>zola</span>
        </span>
      </p>
    </div>
  </footer>
  

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/galleria@1.6.1/dist/galleria.min.js" integrity="sha384-QSfwGT8/EU536DKdtyP2D6SLlh8zBaZ0cVkwfrwhqzIU9VCfJT00CLVP5t+HAiYg" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/galleria@1.6.1/dist/themes/folio/galleria.folio.min.js" integrity="sha384-DwpKI+deZB267+hPKwiOIc5Y2GKsVL0mR6hgz7GgIu7AgAMYqJwcJKY1YBNfhWcY" crossorigin="anonymous"></script>
  
  
  <script src="https://cdn.jsdelivr.net/npm/mermaid@8.13.5/dist/mermaid.min.js" integrity="sha384-0yWn54pSGtfKCU+skfA69l25VsCw+MZt4LQov3xNRoS7YkAMrFokGgSBnAWSK4pv" crossorigin="anonymous"></script>
  
  
  <script src="https://cdn.jsdelivr.net/npm/chart.xkcd@1.1.13/dist/chart.xkcd.min.js" integrity="sha384-xC3h1+IHXK8seA+8KfT79Z4e0GPsznjXBoMa5nd8ooWKplPyXx92NOmljWxLC/cs" crossorigin="anonymous"></script>
  
  
  <script src="https://api.mapbox.com/mapbox-gl-js/v2.6.1/mapbox-gl.js" integrity="sha384-Pulw7+h73841BQIK0LzJCydKRPChJUF9w8h8W0o3h+cLtoyNPJS847bQauLWOTwg" crossorigin="anonymous"></script>
  
  <script src="https://nlp-with-fewer-labels.github.io/elasticlunr.min.js"></script>
  <script src="https://nlp-with-fewer-labels.github.io/search_index.en.js"></script><script src="https://nlp-with-fewer-labels.github.io/js/site.js"></script>

  
  

  
  
</body>

</html>
